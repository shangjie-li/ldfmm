import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F

from layers import dla
from layers import dlaup
from utils.heatmap_utils import nms_heatmap
from utils.heatmap_utils import select_topk
from utils.heatmap_utils import get_poi
from utils.loss_utils import focal_loss


def build_model(cfg, num_classes):
    if cfg['type'] == 'LDFMM':
        return LDFMM(
            backbone=cfg['backbone'], neck=cfg['neck'], regress_box2d=cfg['regress_box2d'], num_classes=num_classes,
        )
    else:
        raise NotImplementedError


class LDFMM(nn.Module):
    def __init__(self, backbone, neck, regress_box2d, num_classes, downsample=4):
        super().__init__()
        if backbone == 'DLA34':
            self.backbone = dla.dla34(pretrained=True, return_levels=True)
        else:
            raise NotImplementedError

        channels = self.backbone.channels  # channel list for feature maps generated by the backbone
        assert downsample in [4, 8, 16, 32]
        self.first_level = int(np.log2(downsample))
        scales = [2 ** i for i in range(len(channels[self.first_level:]))]

        if neck == 'DLAUp':
            self.neck = dlaup.DLAUp(channels[self.first_level:], scales_list=scales)
        else:
            raise NotImplementedError

        self.regress_box2d = regress_box2d
        self.heads = {
            'heatmap': num_classes,
            'offset3d': 2,
            'depth_res': 1,
            'size3d': 3,
            'alpha_bin': 12,
            'alpha_res': 12,
        }
        if self.regress_box2d:
            self.heads.update({
                'offset2d': 2,
                'size2d': 2,
            })

        for head in self.heads.keys():
            num_channels = self.heads[head]
            fc = nn.Sequential(
                nn.Conv2d(channels[self.first_level], 256, kernel_size=3, padding=1, bias=True),
                nn.ReLU(inplace=True),
                nn.Conv2d(256, num_channels, kernel_size=1, stride=1, padding=0, bias=True),
            )
            if head == 'heatmap':
                fc[-1].bias.data.fill_(-2.19)
            else:
                self.fill_fc_weights(fc)
            self.__setattr__(head, fc)

    def fill_fc_weights(self, layers):
        for m in layers.modules():
            if isinstance(m, nn.Conv2d):
                nn.init.normal_(m.weight, std=0.001)
                if m.bias is not None:
                    nn.init.constant_(m.bias, 0)

    def forward(self, x):
        feat = self.backbone(x)
        feat = self.neck(feat[self.first_level:])
        ret = {}

        for head in self.heads:
            ret[head] = self.__getattr__(head)(feat)

        return ret

    def select_outputs(self, outputs, K, lidar_maps=None):
        heatmaps = outputs['heatmap']
        batch_size = heatmaps.shape[0]
        heatmaps = torch.clamp(heatmaps.sigmoid_(), min=1e-4, max=1 - 1e-4)

        refined_heatmaps = heatmaps * (lidar_maps[:, 2:3, :, :] > 0)
        refined_heatmaps = nms_heatmap(refined_heatmaps)

        scores, indices, cls_ids, xs, ys = select_topk(refined_heatmaps, K=K)

        offsets3d = get_poi(outputs['offset3d'], indices)
        centers3d_img = torch.stack([xs, ys], dim=2) + offsets3d

        depths_ref = get_poi(lidar_maps, indices)[:, :, 2:3]
        depths_res = get_poi(outputs['depth_res'], indices)

        sizes3d = get_poi(outputs['size3d'], indices)

        alphas_bin = get_poi(outputs['alpha_bin'], indices)
        alphas_res = get_poi(outputs['alpha_res'], indices)

        preds = {
            'heatmap': heatmaps,
            'cls_id': cls_ids.view(batch_size, K, 1),
            'score': scores.view(batch_size, K, 1),
            'center3d_img': centers3d_img.view(batch_size, K, 2),
            'depth_ref': depths_ref.view(batch_size, K, 1),
            'depth_res': depths_res.view(batch_size, K, 1),
            'size3d': sizes3d.view(batch_size, K, 3),
            'alpha_bin': alphas_bin.view(batch_size, K, 12),
            'alpha_res': alphas_res.view(batch_size, K, 12),
        }

        if self.regress_box2d:
            offsets2d = get_poi(outputs['offset2d'], indices)
            centers2d = torch.stack([xs, ys], dim=2) + offsets2d

            sizes2d = get_poi(outputs['size2d'], indices)

            preds.update({
                'center2d': centers2d.view(batch_size, K, 2),
                'size2d': sizes2d.view(batch_size, K, 2),
            })

        return preds

    def compute_loss(self, outputs, targets, lidar_maps):
        try:
            mask = targets['mask'].bool()
        except AttributeError:
            mask = targets['mask']

        gt_keypoints = targets['keypoint']

        heatmaps = outputs['heatmap']
        heatmaps = torch.clamp(heatmaps.sigmoid_(), min=1e-4, max=1 - 1e-4)
        gt_heatmaps = targets['heatmap']
        heatmap_loss = focal_loss(heatmaps, gt_heatmaps)

        offsets3d = get_poi(outputs['offset3d'], gt_keypoints)[mask].view(-1, 2)
        gt_offsets3d = targets['offset3d'][mask].view(-1, 2)
        offset3d_loss = F.l1_loss(offsets3d, gt_offsets3d)

        depths_ref = get_poi(lidar_maps, gt_keypoints)[mask].view(-1, 3)[:, 2:3]
        depths_res = get_poi(outputs['depth_res'], gt_keypoints)[mask].view(-1, 1)
        depths = depths_ref + depths_res
        gt_depths = targets['box3d'][:, :, 2:3][mask].view(-1, 1)
        depth_loss = F.l1_loss(depths, gt_depths)

        sizes3d = get_poi(outputs['size3d'], gt_keypoints)[mask].view(-1, 3)
        gt_sizes3d = targets['box3d'][:, :, 3:6][mask].view(-1, 3)
        size3d_loss = F.l1_loss(sizes3d, gt_sizes3d)

        alphas_bin = get_poi(outputs['alpha_bin'], gt_keypoints)[mask].view(-1, 12)
        gt_alphas_bin = targets['alpha_bin'][mask].view(-1, 1)
        alpha_bin_loss = F.cross_entropy(alphas_bin, gt_alphas_bin.view(-1))

        alphas_res = get_poi(outputs['alpha_res'], gt_keypoints)[mask].view(-1, 12)
        alphas_res = alphas_res.gather(dim=1, index=gt_alphas_bin.view(-1, 1)).view(-1, 1)
        gt_alphas_res = targets['alpha_res'][mask].view(-1, 1)
        alpha_res_loss = F.l1_loss(alphas_res, gt_alphas_res)

        total_loss = heatmap_loss + offset3d_loss + depth_loss + size3d_loss + alpha_bin_loss + alpha_res_loss
        stats_dict = {
            'heatmap': heatmap_loss.item(),
            'offset3d': offset3d_loss.item(),
            'depth': depth_loss.item(),
            'size3d': size3d_loss.item(),
            'alpha_bin': alpha_bin_loss.item(),
            'alpha_res': alpha_res_loss.item(),
        }

        if self.regress_box2d:
            offsets2d = get_poi(outputs['offset2d'], gt_keypoints)[mask].view(-1, 2)
            gt_offsets2d = targets['offset2d'][mask].view(-1, 2)
            offset2d_loss = F.l1_loss(offsets2d, gt_offsets2d)

            sizes2d = get_poi(outputs['size2d'], gt_keypoints)[mask].view(-1, 2)
            gt_sizes2d = targets['box2d'][:, :, 2:4][mask].view(-1, 2)
            size2d_loss = F.l1_loss(sizes2d, gt_sizes2d)

            total_loss += offset2d_loss + size2d_loss
            stats_dict.update({
                'offset2d': offset2d_loss.item(),
                'size2d': size2d_loss.item(),
            })

        return total_loss, stats_dict
